{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JOY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"data/news_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source_id</th>\n",
       "      <th>source_name</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>url_to_image</th>\n",
       "      <th>published_at</th>\n",
       "      <th>content</th>\n",
       "      <th>top_article</th>\n",
       "      <th>engagement_reaction_count</th>\n",
       "      <th>engagement_comment_count</th>\n",
       "      <th>engagement_share_count</th>\n",
       "      <th>engagement_comment_plugin_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8005</th>\n",
       "      <td>8005</td>\n",
       "      <td>cbs-news</td>\n",
       "      <td>CBS News</td>\n",
       "      <td>Emily Tillett</td>\n",
       "      <td>300 former officials call out Trump for \"uncon...</td>\n",
       "      <td>Group of bipartisan national security experts ...</td>\n",
       "      <td>https://www.cbsnews.com/news/donald-trump-ukra...</td>\n",
       "      <td>https://cbsnews2.cbsistatic.com/hub/i/r/2017/0...</td>\n",
       "      <td>2019-09-27T12:17:01Z</td>\n",
       "      <td>More than 300 former national security officia...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14330.0</td>\n",
       "      <td>6414.0</td>\n",
       "      <td>4197.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>9495</td>\n",
       "      <td>cnn</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Jason Hanna and Aaron Cooper, CNN</td>\n",
       "      <td>WWII-era bomber crashes at an airport near Har...</td>\n",
       "      <td>A World War II-era aircraft crashed Wednesday ...</td>\n",
       "      <td>https://www.cnn.com/2019/10/02/us/connecticut-...</td>\n",
       "      <td>https://cdn.cnn.com/cnnnext/dam/assets/1910021...</td>\n",
       "      <td>2019-10-02T14:35:10Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3373.0</td>\n",
       "      <td>988.0</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7428</th>\n",
       "      <td>7428</td>\n",
       "      <td>business-insider</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>lramsey@businessinsider.com (Lydia Ramsey), Ly...</td>\n",
       "      <td>Dispensed: Amazon and Best Buy's expanding hea...</td>\n",
       "      <td>REUTERS/Joshua Roberts Hello, There must be so...</td>\n",
       "      <td>https://www.businessinsider.com/dispensed-week...</td>\n",
       "      <td>https://image.businessinsider.com/5c2f7f05bd77...</td>\n",
       "      <td>2019-09-27T14:13:56Z</td>\n",
       "      <td>Hello,\\r\\nThere must be something in the water...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0         source_id       source_name  \\\n",
       "8005        8005          cbs-news          CBS News   \n",
       "9495        9495               cnn               CNN   \n",
       "7428        7428  business-insider  Business Insider   \n",
       "\n",
       "                                                 author  \\\n",
       "8005                                      Emily Tillett   \n",
       "9495                  Jason Hanna and Aaron Cooper, CNN   \n",
       "7428  lramsey@businessinsider.com (Lydia Ramsey), Ly...   \n",
       "\n",
       "                                                  title  \\\n",
       "8005  300 former officials call out Trump for \"uncon...   \n",
       "9495  WWII-era bomber crashes at an airport near Har...   \n",
       "7428  Dispensed: Amazon and Best Buy's expanding hea...   \n",
       "\n",
       "                                            description  \\\n",
       "8005  Group of bipartisan national security experts ...   \n",
       "9495  A World War II-era aircraft crashed Wednesday ...   \n",
       "7428  REUTERS/Joshua Roberts Hello, There must be so...   \n",
       "\n",
       "                                                    url  \\\n",
       "8005  https://www.cbsnews.com/news/donald-trump-ukra...   \n",
       "9495  https://www.cnn.com/2019/10/02/us/connecticut-...   \n",
       "7428  https://www.businessinsider.com/dispensed-week...   \n",
       "\n",
       "                                           url_to_image          published_at  \\\n",
       "8005  https://cbsnews2.cbsistatic.com/hub/i/r/2017/0...  2019-09-27T12:17:01Z   \n",
       "9495  https://cdn.cnn.com/cnnnext/dam/assets/1910021...  2019-10-02T14:35:10Z   \n",
       "7428  https://image.businessinsider.com/5c2f7f05bd77...  2019-09-27T14:13:56Z   \n",
       "\n",
       "                                                content  top_article  \\\n",
       "8005  More than 300 former national security officia...          0.0   \n",
       "9495                                                NaN          0.0   \n",
       "7428  Hello,\\r\\nThere must be something in the water...          0.0   \n",
       "\n",
       "      engagement_reaction_count  engagement_comment_count  \\\n",
       "8005                    14330.0                    6414.0   \n",
       "9495                     3373.0                     988.0   \n",
       "7428                        0.0                       0.0   \n",
       "\n",
       "      engagement_share_count  engagement_comment_plugin_count  \n",
       "8005                  4197.0                              0.0  \n",
       "9495                  1265.0                              0.0  \n",
       "7428                  1627.0                              0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to clean and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, tokenizer, stopwords):\n",
    "    \"\"\"Pre-process text and generate tokens\n",
    "\n",
    "    Args:\n",
    "        text: Text to tokenize.\n",
    "\n",
    "    Returns:\n",
    "        Tokenized text.\n",
    "    \"\"\"\n",
    "    text = str(text).lower()  # Lowercase words\n",
    "    text = re.sub(r\"\\[(.*?)\\]\", \"\", text)  # Remove [+XYZ chars] in content\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Remove multiple spaces in content\n",
    "    text = re.sub(r\"\\w+…|…\", \"\", text)  # Remove ellipsis (and last word)\n",
    "    text = re.sub(r\"(?<=\\w)-(?=\\w)\", \" \", text)  # Replace dash between words\n",
    "    text = re.sub(\n",
    "        f\"[{re.escape(string.punctuation)}]\", \"\", text\n",
    "    )  # Remove punctuation\n",
    "\n",
    "    tokens = tokenizer(text)  # Get tokens from text\n",
    "    tokens = [t for t in tokens if not t in stopwords]  # Remove stopwords\n",
    "    tokens = [\"\" if t.isdigit() else t for t in tokens]  # Remove digits\n",
    "    tokens = [t for t in tokens if len(t) > 1]  # Remove short tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply function and remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe: (10437, 15)\n",
      "Pre-processed dataframe: (9882, 2)\n"
     ]
    }
   ],
   "source": [
    "custom_stopwords = set(stopwords.words(\"english\") + [\"news\", \"new\", \"top\"])\n",
    "text_columns = [\"title\", \"description\", \"content\"]\n",
    "\n",
    "df = df_raw.copy()\n",
    "df[\"content\"] = df[\"content\"].fillna(\"\")\n",
    "\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "# Create text column based on title, description, and content\n",
    "df[\"text\"] = df[text_columns].apply(lambda x: \" | \".join(x), axis=1)\n",
    "df[\"tokens\"] = df[\"text\"].map(lambda x: clean_text(x, word_tokenize, custom_stopwords))\n",
    "\n",
    "# Remove duplicated after preprocessing\n",
    "_, idx = np.unique(df[\"tokens\"], return_index=True)\n",
    "df = df.iloc[idx, :]\n",
    "\n",
    "# Remove empty values\n",
    "df = df.loc[df.tokens.map(lambda x: len(x) > 0), [\"text\", \"tokens\"]]\n",
    "\n",
    "print(f\"Original dataframe: {df_raw.shape}\")\n",
    "print(f\"Pre-processed dataframe: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df[\"text\"].values\n",
    "tokenized_docs = df[\"tokens\"].values\n",
    "vocab = Counter()\n",
    "for token in tokenized_docs:\n",
    "    vocab.update(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('us', 2757),\n",
       " ('said', 2519),\n",
       " ('year', 1781),\n",
       " ('president', 1756),\n",
       " ('trump', 1705),\n",
       " ('world', 1620),\n",
       " ('says', 1511),\n",
       " ('one', 1418),\n",
       " ('two', 1284),\n",
       " ('first', 1195)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate vectors from document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function for creating a single vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(list_of_docs, model):\n",
    "    \"\"\"Generate vectors for list of documents using a Word Embedding\n",
    "\n",
    "    Args:\n",
    "        list_of_docs: List of documents\n",
    "        model: Gensim's Word Embedding\n",
    "\n",
    "    Returns:\n",
    "        List of document vectors\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    for tokens in list_of_docs:\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in model.wv:\n",
    "                try:\n",
    "                    vectors.append(model.wv[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            features.append(avg_vec)\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply function to previously pre-processed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=tokenized_docs, vector_size=100, workers=1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trumps', 0.988541841506958),\n",
       " ('president', 0.9746480584144592),\n",
       " ('donald', 0.9274919629096985),\n",
       " ('ivanka', 0.9203823804855347),\n",
       " ('impeachment', 0.9195769429206848),\n",
       " ('pences', 0.9152195453643799),\n",
       " ('avlon', 0.9148270487785339),\n",
       " ('biden', 0.9146018624305725),\n",
       " ('breitbart', 0.9143953323364258),\n",
       " ('vice', 0.9067230224609375)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"trump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9882, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_docs = vectorize(tokenized_docs, model=model)\n",
    "len(vectorized_docs), len(vectorized_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and analyze clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbkmeans_clusters(X, k, mb=500, print_silhouette_values=False):\n",
    "    \"\"\"Generate clusters.\n",
    "\n",
    "    Args:\n",
    "        X: Matrix of features.\n",
    "        k: Number of clusters.\n",
    "        mb: Size of mini-batches. Defaults to 500.\n",
    "        print_silhouette_values: Print silhouette values per cluster.\n",
    "\n",
    "    Returns:\n",
    "        Trained clustering model and labels based on X.\n",
    "    \"\"\"\n",
    "    km = MiniBatchKMeans(n_clusters=k, batch_size=mb).fit(X)\n",
    "    print(f\"For n_clusters = {k}\")\n",
    "    print(f\"Silhouette coefficient: {silhouette_score(X, km.labels_):0.2f}\")\n",
    "    print(f\"Inertia:{km.inertia_}\")\n",
    "\n",
    "    if print_silhouette_values:\n",
    "        sample_silhouette_values = silhouette_samples(X, km.labels_)\n",
    "        print(f\"Silhouette values:\")\n",
    "        silhouette_values = []\n",
    "        for i in range(k):\n",
    "            cluster_silhouette_values = sample_silhouette_values[km.labels_ == i]\n",
    "            silhouette_values.append(\n",
    "                (\n",
    "                    i,\n",
    "                    cluster_silhouette_values.shape[0],\n",
    "                    cluster_silhouette_values.mean(),\n",
    "                    cluster_silhouette_values.min(),\n",
    "                    cluster_silhouette_values.max(),\n",
    "                )\n",
    "            )\n",
    "        silhouette_values = sorted(\n",
    "            silhouette_values, key=lambda tup: tup[2], reverse=True\n",
    "        )\n",
    "        for s in silhouette_values:\n",
    "            print(\n",
    "                f\"    Cluster {s[0]}: Size:{s[1]} | Avg:{s[2]:.2f} | Min:{s[3]:.2f} | Max: {s[4]:.2f}\"\n",
    "            )\n",
    "    return km, km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 50\n",
      "Silhouette coefficient: 0.11\n",
      "Inertia:3580.118044419166\n",
      "Silhouette values:\n",
      "    Cluster 25: Size:51 | Avg:0.38 | Min:-0.05 | Max: 0.59\n",
      "    Cluster 2: Size:124 | Avg:0.30 | Min:-0.02 | Max: 0.49\n",
      "    Cluster 29: Size:23 | Avg:0.29 | Min:0.01 | Max: 0.50\n",
      "    Cluster 17: Size:88 | Avg:0.28 | Min:-0.14 | Max: 0.51\n",
      "    Cluster 48: Size:82 | Avg:0.27 | Min:0.01 | Max: 0.47\n",
      "    Cluster 19: Size:100 | Avg:0.26 | Min:-0.04 | Max: 0.44\n",
      "    Cluster 28: Size:104 | Avg:0.24 | Min:-0.04 | Max: 0.48\n",
      "    Cluster 3: Size:115 | Avg:0.24 | Min:-0.05 | Max: 0.40\n",
      "    Cluster 23: Size:83 | Avg:0.23 | Min:0.03 | Max: 0.41\n",
      "    Cluster 30: Size:58 | Avg:0.22 | Min:-0.11 | Max: 0.47\n",
      "    Cluster 44: Size:139 | Avg:0.20 | Min:-0.04 | Max: 0.41\n",
      "    Cluster 26: Size:241 | Avg:0.19 | Min:-0.13 | Max: 0.41\n",
      "    Cluster 41: Size:550 | Avg:0.18 | Min:-0.04 | Max: 0.40\n",
      "    Cluster 16: Size:442 | Avg:0.17 | Min:0.00 | Max: 0.37\n",
      "    Cluster 4: Size:95 | Avg:0.15 | Min:-0.06 | Max: 0.40\n",
      "    Cluster 27: Size:129 | Avg:0.14 | Min:-0.12 | Max: 0.36\n",
      "    Cluster 42: Size:210 | Avg:0.13 | Min:-0.10 | Max: 0.36\n",
      "    Cluster 10: Size:148 | Avg:0.13 | Min:-0.04 | Max: 0.31\n",
      "    Cluster 49: Size:101 | Avg:0.13 | Min:-0.06 | Max: 0.32\n",
      "    Cluster 32: Size:96 | Avg:0.13 | Min:-0.09 | Max: 0.35\n",
      "    Cluster 13: Size:128 | Avg:0.12 | Min:-0.11 | Max: 0.36\n",
      "    Cluster 37: Size:76 | Avg:0.12 | Min:-0.15 | Max: 0.34\n",
      "    Cluster 40: Size:227 | Avg:0.12 | Min:-0.09 | Max: 0.32\n",
      "    Cluster 8: Size:44 | Avg:0.12 | Min:-0.16 | Max: 0.33\n",
      "    Cluster 18: Size:198 | Avg:0.12 | Min:-0.05 | Max: 0.35\n",
      "    Cluster 34: Size:415 | Avg:0.11 | Min:-0.09 | Max: 0.31\n",
      "    Cluster 24: Size:463 | Avg:0.11 | Min:-0.06 | Max: 0.32\n",
      "    Cluster 0: Size:297 | Avg:0.11 | Min:-0.12 | Max: 0.31\n",
      "    Cluster 45: Size:121 | Avg:0.10 | Min:-0.12 | Max: 0.29\n",
      "    Cluster 9: Size:266 | Avg:0.10 | Min:-0.06 | Max: 0.29\n",
      "    Cluster 11: Size:121 | Avg:0.10 | Min:-0.08 | Max: 0.32\n",
      "    Cluster 47: Size:443 | Avg:0.10 | Min:-0.07 | Max: 0.31\n",
      "    Cluster 15: Size:220 | Avg:0.10 | Min:-0.13 | Max: 0.29\n",
      "    Cluster 31: Size:218 | Avg:0.10 | Min:-0.12 | Max: 0.29\n",
      "    Cluster 6: Size:205 | Avg:0.08 | Min:-0.16 | Max: 0.28\n",
      "    Cluster 33: Size:214 | Avg:0.07 | Min:-0.14 | Max: 0.27\n",
      "    Cluster 5: Size:90 | Avg:0.07 | Min:-0.10 | Max: 0.31\n",
      "    Cluster 7: Size:339 | Avg:0.06 | Min:-0.18 | Max: 0.33\n",
      "    Cluster 43: Size:232 | Avg:0.06 | Min:-0.11 | Max: 0.28\n",
      "    Cluster 14: Size:212 | Avg:0.05 | Min:-0.18 | Max: 0.30\n",
      "    Cluster 21: Size:194 | Avg:0.05 | Min:-0.16 | Max: 0.25\n",
      "    Cluster 1: Size:179 | Avg:0.05 | Min:-0.14 | Max: 0.21\n",
      "    Cluster 22: Size:174 | Avg:0.04 | Min:-0.15 | Max: 0.25\n",
      "    Cluster 12: Size:577 | Avg:0.04 | Min:-0.16 | Max: 0.23\n",
      "    Cluster 39: Size:240 | Avg:0.03 | Min:-0.23 | Max: 0.26\n",
      "    Cluster 36: Size:242 | Avg:0.03 | Min:-0.10 | Max: 0.19\n",
      "    Cluster 35: Size:220 | Avg:0.03 | Min:-0.17 | Max: 0.27\n",
      "    Cluster 20: Size:289 | Avg:0.01 | Min:-0.16 | Max: 0.21\n",
      "    Cluster 38: Size:135 | Avg:-0.01 | Min:-0.18 | Max: 0.19\n",
      "    Cluster 46: Size:124 | Avg:-0.03 | Min:-0.25 | Max: 0.19\n"
     ]
    }
   ],
   "source": [
    "clustering, cluster_labels = mbkmeans_clusters(X=vectorized_docs, k=50, print_silhouette_values=True)\n",
    "df_clusters = pd.DataFrame({\n",
    "    \"text\": docs,\n",
    "    \"tokens\": [\" \".join(text) for text in tokenized_docs],\n",
    "    \"cluster\": cluster_labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster (based on centroids):\n",
      "Cluster 0: panel buttigieg hill rogue opposing \n",
      "Cluster 1: mosquito collapsed train boats borne \n",
      "Cluster 2: pm johnsons proposals delay benjamin \n",
      "Cluster 3: entertainment likes calloway patch contact \n",
      "Cluster 4: girl boy whose apartment raping \n",
      "Cluster 5: delegation amid erdogan envoy undermine \n",
      "Cluster 6: tournament victory injury beat finished \n",
      "Cluster 7: professional expensive virtual edition ones \n",
      "Cluster 8: category humberto tropical landfall strengthened \n",
      "Cluster 9: repeal urged renewed kiev agencies \n",
      "Cluster 10: knife indiana pleaded duluth arizona \n",
      "Cluster 11: speech dominic israels block suspend \n",
      "Cluster 12: asian followed gained sep gain \n",
      "Cluster 13: bomb dozens kills soldiers victims \n",
      "Cluster 14: glasgow father jailed daughter accident \n",
      "Cluster 15: vizcarra congressional ukrainian aides volodymyr \n",
      "Cluster 16: orleans training corps follows male \n",
      "Cluster 17: tanker ablaze yemen arabian strikes \n",
      "Cluster 18: obama moat blower tweet republicans \n",
      "Cluster 19: squad qualifying warm foursomes finals \n",
      "Cluster 20: total december plunged spring gap \n",
      "Cluster 21: 20th april decided lane haul \n",
      "Cluster 22: moscow zurich environmental stockholm source \n",
      "Cluster 23: charleston category humberto ravaged floodwaters \n",
      "Cluster 24: january formula minutes prize winner \n",
      "Cluster 25: noaa sharpie claim assertions forecasters \n",
      "Cluster 26: cnnpolitics zelensky clinton giuliani volodymyr \n",
      "Cluster 27: tariff tensions lift dispute flows \n",
      "Cluster 28: unrest clearing defied protesters demonstrators \n",
      "Cluster 29: solution centrifuges introduce expressed merkel \n",
      "Cluster 30: cnns transcript interested ridiculed contributor \n",
      "Cluster 31: occupied defence jim parties action \n",
      "Cluster 32: stabbing amber guyger guilty botham \n",
      "Cluster 33: arrest funeral illinois french brazilian \n",
      "Cluster 34: placed overhaul dr anthony elliott \n",
      "Cluster 35: test bowl appearances winner prize \n",
      "Cluster 36: operations preliminary illegally nato freed \n",
      "Cluster 37: brace destruction relief powerful torrential \n",
      "Cluster 38: lower crisis flows gm brazil \n",
      "Cluster 39: stripe employers revenue investing companys \n",
      "Cluster 40: collision river scene relatives broke \n",
      "Cluster 41: edge featuring studio cool drink \n",
      "Cluster 42: dealt edinburgh tafida jodie adrian \n",
      "Cluster 43: presented significant announcement vowed junior \n",
      "Cluster 44: mps referendum proposal delay jo \n",
      "Cluster 45: providing opinions benefits smile views \n",
      "Cluster 46: ai popularity supposedly access radar \n",
      "Cluster 47: suffered born belgium tall drive \n",
      "Cluster 48: trying serial shocked filmed contained \n",
      "Cluster 49: islands charleston flooding ravaged outer \n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster (based on centroids):\")\n",
    "for i in range(50):\n",
    "    tokens_per_cluster = \"\"\n",
    "    most_representative = model.wv.most_similar(positive=[clustering.cluster_centers_[i]], topn=5)\n",
    "    for t in most_representative:\n",
    "        tokens_per_cluster += f\"{t[0]} \"\n",
    "    print(f\"Cluster {i}: {tokens_per_cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US woman arrested at Manila airport with baby hidden in bag | Get breaking national and world news, broadcast video coverage, and exclusive interviews. Find the top news online at ABC news. | An American woman who attempted to carry a 6-day-old baby out of the Philippines hidden inside a sling bag has been arrested at Manila's airport and charged with human trafficking, officials said Thursday.\r\n",
      "They said Jennifer Talbot was able to pass through t… [+1496 chars]\n",
      "-------------\n",
      "Police: No evidence of shooting at northern Virginia mall | Get breaking national and world news, broadcast video coverage, and exclusive interviews. Find the top news online at ABC news. | Authorities in northern Virginia say they have found no evidence that a shooting occurred at a popular mall.\r\n",
      "The Arlington County Police Department tweeted Saturday night that authorities were continuing to conduct a search at the Ballston Quarter mall in Ar… [+162 chars]\n",
      "-------------\n",
      "12th man arrested in statutory rape case at Alabama college | Get breaking national and world news, broadcast video coverage, and exclusive interviews. Find the top news online at ABC news. | A dozen young men are now charged in connection with the alleged rapes of two underage teens at Alabama's Jacksonville State University.\r\n",
      "News outlets reports that an 11th and 12th suspect were arrested Monday.\r\n",
      "Investigators say two underage girls between th… [+504 chars]\n",
      "-------------\n",
      "Chicago boy, 1, stable after falling from 4th-story window | Get breaking national and world news, broadcast video coverage, and exclusive interviews. Find the top news online at ABC news. | Chicago police say a 1-year-old boy is hospitalized after falling from a residential building's fourth-story window.\r\n",
      "Police say the boy fell about 8:25 p.m. Monday from the Parkway Gardens Homes apartment complex. He was taken to Comer Children's Hospital, w… [+610 chars]\n",
      "-------------\n",
      "Fetal remains found in Illinois home of doctor who died | Get breaking national and world news, broadcast video coverage, and exclusive interviews. Find the top news online at ABC news. | More than 2,200 medically preserved fetal remains have been found at the Illinois home of a former Indiana abortion clinic doctor who died last week.\r\n",
      "The Will County Sheriff's Office said in a news release that an attorney for Dr. Ulrich Klopfer's family con… [+536 chars]\n",
      "-------------\n",
      "S Carolina jurors haunted by case of dad who killed 5 kids | Get breaking national and world news, broadcast video coverage, and exclusive interviews. Find the top news online at ABC news. | Nearly half of the jurors who sentenced a South Carolina man to death for killing his five kids say they're haunted by what they heard in court.\r\n",
      "Eight of the 18 jurors who made the unanimous decision for Timothy Jones Jr. to die told The State newspaper they… [+618 chars]\n",
      "-------------\n",
      "Jury selection begins in killing of pregnant woman, officer | Get breaking national and world news, broadcast video coverage, and exclusive interviews. Find the top news online at ABC news. | Jury selection has begun for a man accused of killing his pregnant ex-girlfriend and a Florida police officer.\r\n",
      "The Orlando Sentinel reports that Circuit Judge Leticia Marques told potential jurors Friday that if selected for the 12-member panel, they would b… [+618 chars]\n",
      "-------------\n",
      "Coast Guard lieutenant who prosecutors said plotted a mass killing pleads guilty to gun and drug charges, faces 31 years | Get breaking national and world news, broadcast video coverage, and exclusive interviews. Find the top news online at ABC news. | Coast Guard lieutenant who prosecutors said plotted a mass killing pleads guilty to gun and drug charges, faces 31 years.\n",
      "-------------\n",
      "Driver dies and 7 children are injured as school bus crashes | Get breaking national and world news, broadcast video coverage, and exclusive interviews. Find the top news online at ABC news. | A school bus driver is dead and seven children are injured as a school bus rolled over in northern Mississippi.\r\n",
      "The Mississippi Highway Patrol tells local news outlets that the driver died in the Tuesday morning incident, with the bus ending up on its side i… [+472 chars]\n",
      "-------------\n",
      "U of Illinois student arrested after noose found in elevator | Get breaking national and world news, broadcast video coverage, and exclusive interviews. Find the top news online at ABC news. | The University of Illinois says a student has been arrested after a noose was found hanging in an elevator at a residence hall.\r\n",
      "The university and the Champaign County Sheriff's Office says a 19-year-old student was due to be arraigned Tuesday on disorderly … [+453 chars]\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "test_cluster = 48\n",
    "most_representative_docs = np.argsort(\n",
    "    np.linalg.norm(vectorized_docs - clustering.cluster_centers_[test_cluster], axis=1)\n",
    ")\n",
    "for d in most_representative_docs[:10]:\n",
    "    print(docs[d])\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
